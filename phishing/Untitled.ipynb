{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8263d4-5059-4d8d-b6a8-3f66a35bf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 0) Reset & Imports =====\n",
    "# 환경 설정: tf_env 사용\n",
    "import os\n",
    "os.environ['CONDA_DEFAULT_ENV'] = 'tf_env'\n",
    "\n",
    "import gc, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90520d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 경로: /opt/anaconda3/envs/tf_env/bin/python\n",
      "Python 버전: 3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 08:47:03) [Clang 18.1.8 ]\n",
      "TensorFlow 버전: 2.18.0\n",
      "\n",
      "설치된 패키지 일부:\n"
     ]
    }
   ],
   "source": [
    "# Python 환경 확인\n",
    "import sys\n",
    "print(\"Python 경로:\", sys.executable)\n",
    "print(\"Python 버전:\", sys.version)\n",
    "\n",
    "# 설치된 패키지 확인\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"TensorFlow 버전:\", tf.__version__)\n",
    "except ImportError as e:\n",
    "    print(\"TensorFlow 임포트 실패:\", e)\n",
    "    \n",
    "# pip 경로 확인\n",
    "import subprocess\n",
    "result = subprocess.run([sys.executable, '-m', 'pip', 'list'], capture_output=True, text=True)\n",
    "print(\"\\n설치된 패키지 일부:\")\n",
    "for line in result.stdout.split('\\n')[:10]:\n",
    "    if 'tensor' in line.lower():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a032a0ab-7fd3-4252-882f-02d1412a8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 초기화\n",
    "try: del model\n",
    "except: pass\n",
    "gc.collect()\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42); tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2755837-2f19-4330-9385-36cf47073f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Config =====\n",
    "# Use the repo-local TFLite-ready CSV so feature names/order match mobile assets\n",
    "DATA_PATH = \"phishing/phishing_data_tflite_ready.csv\"\n",
    "TARGET = \"status\"\n",
    "BATCH_SIZE, EPOCHS = 64, 50\n",
    "# LABEL_MODE selects training target: 'soft' uses probability labels, 'binary' uses 0/1, 'both' keeps both and defaults to soft training\n",
    "LABEL_MODE = 'both'  # options: 'soft' | 'binary' | 'both'\n",
    "EARLY_STOP_AT_ACC = 0.95\n",
    "# ===== 2) Load & Clean =====\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if \"url\" in df.columns: df = df.drop(columns=[\"url\"])\n",
    "df = shuffle(df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68322c57-07f9-4074-8e65-287c1a7e6f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/ipykernel_51029/3695572819.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[TARGET] = df[TARGET].astype(str).replace({\"legitimate\":0, \"phishing\":1})\n",
      "/var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/ipykernel_51029/3695572819.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({\"zero\":0,\"one\":1,\"Zero\":0,\"One\":1})\n"
     ]
    }
   ],
   "source": [
    "# 라벨 정리 (soft/binary 병행) — 마지막 컬럼 'status' 원본을 보존해서 소프트 라벨을 유지합니다.\n",
    "# 1) 공통 문자열 매핑(대소문자 무시) -> 문자열 매핑을 numeric 문자열로 바꿔 놓음\n",
    "df[TARGET] = df[TARGET].astype(str).str.strip().str.lower().replace({'legitimate': '0', 'phishing': '1'})\n",
    "# 2) 텍스트 토큰 치환(혹시 남아있는 표현 처리)\n",
    "df = df.replace({'zero': 0, 'one': 1, 'Zero': 0, 'One': 1})\n",
    "# 3) 안전하게 숫자형으로 변환 후 float32로 캐스팅 — 이 값은 soft 라벨로 사용 가능\n",
    "df['label_soft'] = pd.to_numeric(df[TARGET], errors=\"coerce\").astype(\"float32\")\n",
    "# 4) label_soft의 범위를 검사하고 이상치(범위 밖)을 보고\n",
    "print('label_soft min/max/mean:', df['label_soft'].min(), df['label_soft'].max(), df['label_soft'].mean())\n",
    "# 5) hard binary label 생성 (앱/배포 호환성 용도)\n",
    "df['label_binary'] = (df['label_soft'] >= 0.5).astype('float32')\n",
    "print('Label counts (soft approx):', df['label_soft'].value_counts().head(10).to_dict())\n",
    "print('Label counts (binary):', df['label_binary'].value_counts().to_dict())\n",
    "# Note: we keep both label_soft and label_binary in the dataframe; training target selection controlled by LABEL_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7006c5fe-98b5-4ecb-8c0a-228c61b6cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) 숫자 피처만 안전하게 선택 =====\n",
    "feature_cols = [c for c in df.columns if c != TARGET]\n",
    "numeric_cols = []\n",
    "for c in feature_cols:\n",
    "    ser = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    if ser.notna().any():           # 전부 NaN이 아니면 사용\n",
    "        df[c] = ser\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "assert len(numeric_cols) > 0, \"사용 가능한 숫자 피처가 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc18bd6-4637-4da0-8aa1-a8ec0a6b12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (9184, 87)  | X_val: (2297, 87)  | n_features: 87\n"
     ]
    }
   ],
   "source": [
    "# 결측치 중앙값으로 채우기\n",
    "for c in numeric_cols:\n",
    "    med = float(df[c].dropna().median()) if df[c].notna().any() else 0.0\n",
    "    df[c] = df[c].fillna(med).astype(\"float32\")\n",
    "\n",
    "# ===== 4) 행렬(X, y)로 변환 =====\n",
    "X = df[numeric_cols].to_numpy(dtype=\"float32\")\n",
    "# Prepare soft and binary targets — do not overwrite original soft values\n",
    "y_soft = df['label_soft'].to_numpy(dtype=\"float32\")\n",
    "y_binary = df['label_binary'].to_numpy(dtype=\"float32\")\n",
    "# Choose training target based on LABEL_MODE (soft | binary | both). 'both' will train using soft by default\n",
    "if LABEL_MODE == 'soft':\n",
    "    y = y_soft\n",
    "elif LABEL_MODE == 'binary':\n",
    "    y = y_binary\n",
    "else:  # 'both' default to soft for training but keep binary for evaluation/export\n",
    "    y = y_soft\n",
    "\n",
    "\n",
    "# Use index-based split so soft and binary targets align with the same train/validation indices\n",
    "indices = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=y_binary, random_state=42)\n",
    "X_train, X_val = X[train_idx], X[val_idx]\n",
    "# aligned splits for both target types\n",
    "y_soft_train, y_soft_val = y_soft[train_idx], y_soft[val_idx]\n",
    "y_binary_train, y_binary_val = y_binary[train_idx], y_binary[val_idx]\n",
    "if LABEL_MODE == 'soft':\n",
    "    y_train, y_val = y_soft_train, y_soft_val\n",
    "elif LABEL_MODE == 'binary':\n",
    "    y_train, y_val = y_binary_train, y_binary_val\n",
    "else:  # both - default to soft training, keep binary for evaluation\n",
    "    y_train, y_val = y_soft_train, y_soft_val\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \" | X_val:\", X_val.shape, \" | n_features:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbeb252-e2ed-4e31-b0d7-0feb6df67368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"phish_numeric_only\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"phish_numeric_only\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ norm_all (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">175</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ features (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ norm_all (\u001b[38;5;33mNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m)             │           \u001b[38;5;34m175\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,920</span> (30.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,920\u001b[0m (30.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,745</span> (30.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,745\u001b[0m (30.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175</span> (704.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m175\u001b[0m (704.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 5) 모델 (단일 입력) =====\n",
    "inp = keras.Input(shape=(X_train.shape[1],), name=\"features\", dtype=tf.float32)\n",
    "norm = layers.Normalization(name=\"norm_all\")\n",
    "norm.adapt(X_train)\n",
    "\n",
    "x = norm(inp)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inp, outputs=out, name=\"phish_numeric_only\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992483d-0794-444d-9f7d-b45ad29ba174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8344 - loss: 0.3833 - val_accuracy: 0.9303 - val_loss: 0.1842\n",
      "Epoch 2/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8344 - loss: 0.3833 - val_accuracy: 0.9303 - val_loss: 0.1842\n",
      "Epoch 2/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9414 - loss: 0.1591 - val_accuracy: 0.9465 - val_loss: 0.1400\n",
      "Epoch 3/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9414 - loss: 0.1591 - val_accuracy: 0.9465 - val_loss: 0.1400\n",
      "Epoch 3/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9526 - loss: 0.1330 - val_accuracy: 0.9525 - val_loss: 0.1264\n",
      "Epoch 4/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9526 - loss: 0.1330 - val_accuracy: 0.9525 - val_loss: 0.1264\n",
      "Epoch 4/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9583 - loss: 0.1153 - val_accuracy: 0.9560 - val_loss: 0.1187\n",
      "Epoch 5/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9583 - loss: 0.1153 - val_accuracy: 0.9560 - val_loss: 0.1187\n",
      "Epoch 5/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9627 - loss: 0.1058 - val_accuracy: 0.9621 - val_loss: 0.1129\n",
      "Epoch 6/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9627 - loss: 0.1058 - val_accuracy: 0.9621 - val_loss: 0.1129\n",
      "Epoch 6/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9639 - loss: 0.0968 - val_accuracy: 0.9608 - val_loss: 0.1099\n",
      "Epoch 7/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9639 - loss: 0.0968 - val_accuracy: 0.9608 - val_loss: 0.1099\n",
      "Epoch 7/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9664 - loss: 0.0926 - val_accuracy: 0.9630 - val_loss: 0.1088\n",
      "Epoch 8/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9664 - loss: 0.0926 - val_accuracy: 0.9630 - val_loss: 0.1088\n",
      "Epoch 8/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9686 - loss: 0.0876 - val_accuracy: 0.9656 - val_loss: 0.1040\n",
      "Epoch 9/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9686 - loss: 0.0876 - val_accuracy: 0.9656 - val_loss: 0.1040\n",
      "Epoch 9/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9721 - loss: 0.0811 - val_accuracy: 0.9695 - val_loss: 0.0999\n",
      "Epoch 10/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9721 - loss: 0.0811 - val_accuracy: 0.9695 - val_loss: 0.0999\n",
      "Epoch 10/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9759 - loss: 0.0739 - val_accuracy: 0.9691 - val_loss: 0.1008\n",
      "Epoch 11/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9759 - loss: 0.0739 - val_accuracy: 0.9691 - val_loss: 0.1008\n",
      "Epoch 11/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9743 - loss: 0.0722 - val_accuracy: 0.9678 - val_loss: 0.1006\n",
      "Epoch 12/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9743 - loss: 0.0722 - val_accuracy: 0.9678 - val_loss: 0.1006\n",
      "Epoch 12/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9743 - loss: 0.0705 - val_accuracy: 0.9717 - val_loss: 0.0944\n",
      "Epoch 13/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9743 - loss: 0.0705 - val_accuracy: 0.9717 - val_loss: 0.0944\n",
      "Epoch 13/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9789 - loss: 0.0643 - val_accuracy: 0.9730 - val_loss: 0.0943\n",
      "Epoch 14/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9789 - loss: 0.0643 - val_accuracy: 0.9730 - val_loss: 0.0943\n",
      "Epoch 14/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9799 - loss: 0.0606 - val_accuracy: 0.9717 - val_loss: 0.0915\n",
      "Epoch 15/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9799 - loss: 0.0606 - val_accuracy: 0.9717 - val_loss: 0.0915\n",
      "Epoch 15/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9796 - loss: 0.0595 - val_accuracy: 0.9730 - val_loss: 0.0907\n",
      "Epoch 16/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9796 - loss: 0.0595 - val_accuracy: 0.9730 - val_loss: 0.0907\n",
      "Epoch 16/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9816 - loss: 0.0560 - val_accuracy: 0.9739 - val_loss: 0.0920\n",
      "Epoch 17/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9816 - loss: 0.0560 - val_accuracy: 0.9739 - val_loss: 0.0920\n",
      "Epoch 17/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9826 - loss: 0.0515 - val_accuracy: 0.9743 - val_loss: 0.0885\n",
      "Epoch 18/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9826 - loss: 0.0515 - val_accuracy: 0.9743 - val_loss: 0.0885\n",
      "Epoch 18/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9827 - loss: 0.0518 - val_accuracy: 0.9743 - val_loss: 0.0890\n",
      "Epoch 19/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9827 - loss: 0.0518 - val_accuracy: 0.9743 - val_loss: 0.0890\n",
      "Epoch 19/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9823 - loss: 0.0512 - val_accuracy: 0.9734 - val_loss: 0.0978\n",
      "Epoch 20/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9823 - loss: 0.0512 - val_accuracy: 0.9734 - val_loss: 0.0978\n",
      "Epoch 20/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9839 - loss: 0.0490 - val_accuracy: 0.9756 - val_loss: 0.0886\n",
      "Epoch 21/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9839 - loss: 0.0490 - val_accuracy: 0.9756 - val_loss: 0.0886\n",
      "Epoch 21/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9834 - loss: 0.0493 - val_accuracy: 0.9765 - val_loss: 0.0882\n",
      "Epoch 22/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9834 - loss: 0.0493 - val_accuracy: 0.9765 - val_loss: 0.0882\n",
      "Epoch 22/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9840 - loss: 0.0469 - val_accuracy: 0.9778 - val_loss: 0.0884\n",
      "Epoch 23/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9840 - loss: 0.0469 - val_accuracy: 0.9778 - val_loss: 0.0884\n",
      "Epoch 23/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9854 - loss: 0.0430 - val_accuracy: 0.9765 - val_loss: 0.0895\n",
      "Epoch 24/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9854 - loss: 0.0430 - val_accuracy: 0.9765 - val_loss: 0.0895\n",
      "Epoch 24/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9855 - loss: 0.0398 - val_accuracy: 0.9756 - val_loss: 0.0903\n",
      "Epoch 25/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9855 - loss: 0.0398 - val_accuracy: 0.9756 - val_loss: 0.0903\n",
      "Epoch 25/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9860 - loss: 0.0404 - val_accuracy: 0.9774 - val_loss: 0.0875\n",
      "Epoch 26/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9860 - loss: 0.0404 - val_accuracy: 0.9774 - val_loss: 0.0875\n",
      "Epoch 26/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9853 - loss: 0.0388 - val_accuracy: 0.9782 - val_loss: 0.0871\n",
      "Epoch 27/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9853 - loss: 0.0388 - val_accuracy: 0.9782 - val_loss: 0.0871\n",
      "Epoch 27/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9868 - loss: 0.0370 - val_accuracy: 0.9743 - val_loss: 0.0877\n",
      "Epoch 28/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9868 - loss: 0.0370 - val_accuracy: 0.9743 - val_loss: 0.0877\n",
      "Epoch 28/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9870 - loss: 0.0343 - val_accuracy: 0.9774 - val_loss: 0.0904\n",
      "Epoch 29/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9870 - loss: 0.0343 - val_accuracy: 0.9774 - val_loss: 0.0904\n",
      "Epoch 29/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9875 - loss: 0.0355 - val_accuracy: 0.9795 - val_loss: 0.0858\n",
      "Epoch 30/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9875 - loss: 0.0355 - val_accuracy: 0.9795 - val_loss: 0.0858\n",
      "Epoch 30/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9902 - loss: 0.0336 - val_accuracy: 0.9765 - val_loss: 0.0902\n",
      "Epoch 31/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9902 - loss: 0.0336 - val_accuracy: 0.9765 - val_loss: 0.0902\n",
      "Epoch 31/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9888 - loss: 0.0335 - val_accuracy: 0.9778 - val_loss: 0.0892\n",
      "Epoch 32/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9888 - loss: 0.0335 - val_accuracy: 0.9778 - val_loss: 0.0892\n",
      "Epoch 32/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9895 - loss: 0.0296 - val_accuracy: 0.9769 - val_loss: 0.0917\n",
      "Epoch 33/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9895 - loss: 0.0296 - val_accuracy: 0.9769 - val_loss: 0.0917\n",
      "Epoch 33/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9901 - loss: 0.0300 - val_accuracy: 0.9774 - val_loss: 0.0870\n",
      "Epoch 34/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9901 - loss: 0.0300 - val_accuracy: 0.9774 - val_loss: 0.0870\n",
      "Epoch 34/50\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9903 - loss: 0.0291 - val_accuracy: 0.9774 - val_loss: 0.0907\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9903 - loss: 0.0291 - val_accuracy: 0.9774 - val_loss: 0.0907\n"
     ]
    }
   ],
   "source": [
    "# ===== 6) 콜백 & 학습 =====\n",
    "# class StopAtAcc(keras.callbacks.Callback):\n",
    "#     def __init__(self, target=EARLY_STOP_AT_ACC): super().__init__(); self.target=target\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         if logs and logs.get(\"accuracy\",0) >= self.target:\n",
    "#             print(f\"\\nReached {self.target*100:.0f}% accuracy — stopping.\")\n",
    "#             self.model.stop_training = True\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     callbacks=[StopAtAcc()]\n",
    "# )\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Prepare sample weights when using soft labels: down-weight uncertain samples (near 0.5)\n",
    "sample_weight = None\n",
    "val_sample_weight = None\n",
    "if LABEL_MODE == 'soft':\n",
    "    sw = np.abs(y_train - 0.5) * 2.0  # maps distance to 0..1\n",
    "    sw = np.clip(sw, 0.1, 1.0)  # floor to avoid zero weights\n",
    "    sample_weight = sw\n",
    "    vsw = np.abs(y_val - 0.5) * 2.0\n",
    "    val_sample_weight = np.clip(vsw, 0.1, 1.0)\n",
    "    print('Sample weight [train] min/max/mean:', sample_weight.min(), sample_weight.max(), sample_weight.mean())\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val, val_sample_weight) if val_sample_weight is not None else (X_val, y_val),\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "    callbacks=[es],\n",
    "    sample_weight=sample_weight,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EVAL: validation metrics (soft & binary aware) =====\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# predict probabilities\n",
    "preds = model.predict(X_val).flatten()\n",
    "eps = 1e-7\n",
    "preds_clipped = np.clip(preds, eps, 1.0 - eps)\n",
    "# decide which true labels to use\n",
    "if LABEL_MODE == 'soft':\n",
    "    y_true_soft = y_val\n",
    "    y_true_binary = (y_val >= 0.5).astype('float32')\n",
    "elif LABEL_MODE == 'binary':\n",
    "    y_true_binary = y_val\n",
    "    y_true_soft = y_soft_val if 'y_soft_val' in globals() else y_true_binary.astype('float32')\n",
    "else:  # both\n",
    "    y_true_soft = y_soft_val\n",
    "    y_true_binary = y_binary_val\n",
    "# logloss (works with soft targets)\n",
    "logloss = -np.mean(y_true_soft * np.log(preds_clipped) + (1 - y_true_soft) * np.log(1 - preds_clipped))\n",
    "# AUC & Accuracy (binary metrics)\n",
    "auc = roc_auc_score(y_true_binary, preds)\n",
    "acc = np.mean((preds >= 0.5).astype('float32') == y_true_binary)\n",
    "print('Validation results: logloss={:.6f}, AUC={:.4f}, accuracy={:.4f}'.format(logloss, auc, acc))\n",
    "print('preds mean/min/max:', preds.mean(), preds.min(), preds.max())\n",
    "print('soft-label stats: min/max/mean', y_true_soft.min(), y_true_soft.max(), y_true_soft.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "378d8e4c-dce4-4fd9-93de-0349c29e21dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 7) Plot =====\n",
    "# acc = history.history.get(\"accuracy\", []); val_acc = history.history.get(\"val_accuracy\", [])\n",
    "# plt.figure(); plt.plot(range(1,len(acc)+1), acc, label=\"acc\"); plt.plot(range(1,len(val_acc)+1), val_acc, label=\"val_acc\")\n",
    "# plt.xlabel(\"Epochs\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.title(\"Training vs Validation\"); plt.show()\n",
    "\n",
    "acc = history.history.get(\"accuracy\", [])\n",
    "val_acc = history.history.get(\"val_accuracy\", [])\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, label=\"acc\")\n",
    "plt.plot(epochs, val_acc, label=\"val_acc\")\n",
    "plt.ylim(0, 1)                         # 🔁 변경점 4: 축 고정으로 왜곡 방지\n",
    "plt.xlabel(\"Epochs\"); plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training vs Validation\")\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba35d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/tmp40jqtk8t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/tmp40jqtk8t/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/tmp40jqtk8t'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 87), dtype=tf.float32, name='features')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13277553552: TensorSpec(shape=(1, 87), dtype=tf.float32, name=None)\n",
      "  13277554320: TensorSpec(shape=(1, 87), dtype=tf.float32, name=None)\n",
      "  13277550864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13277553744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13277552976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13277552400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13277554512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13277552784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TFLite 모델이 저장되었습니다: /Users/seungmin/Desktop/승민/대학/YU/3-2/프로젝트/QR/YU_mobile_kotlin/phishing/phishing_model.tflite\n",
      "피처 정보가 저장되었습니다: /Users/seungmin/Desktop/승민/대학/YU/3-2/프로젝트/QR/YU_mobile_kotlin/phishing/feature_info.json\n",
      "TFLite 모델이 저장되었습니다: /Users/seungmin/Desktop/승민/대학/YU/3-2/프로젝트/QR/YU_mobile_kotlin/phishing/phishing_model.tflite\n",
      "피처 정보가 저장되었습니다: /Users/seungmin/Desktop/승민/대학/YU/3-2/프로젝트/QR/YU_mobile_kotlin/phishing/feature_info.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762222936.805347 13337158 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1762222936.805362 13337158 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-11-04 11:22:16.805473: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/tmp40jqtk8t\n",
      "2025-11-04 11:22:16.805787: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-11-04 11:22:16.805794: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/tmp40jqtk8t\n",
      "2025-11-04 11:22:16.808336: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-11-04 11:22:16.824455: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/nv/tfw2zdqs7031dn83bb91bwdr0000gn/T/tmp40jqtk8t\n",
      "2025-11-04 11:22:16.829250: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 23777 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# ===== 8) TFLite 변환 =====\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# TFLite 모델 저장\n",
    "# Save outputs into the repo-local phishing/ folder\n",
    "tflite_path = \"phishing/phishing_model.tflite\"\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite 모델이 저장되었습니다: {tflite_path}\")\n",
    "\n",
    "# 피처 정보 저장 (Android에서 사용)\n",
    "import json\n",
    "feature_info = {\n",
    "    \"feature_columns\": numeric_cols,\n",
    "    \"input_shape\": [X_train.shape[1]],\n",
    "    \"normalization_layer\": \"norm_all\"\n",
    "}\n",
    "\n",
    "feature_info_path = \"phishing/feature_info.json\"\n",
    "with open(feature_info_path, 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "\n",
    "print(f\"피처 정보가 저장되었습니다: {feature_info_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
